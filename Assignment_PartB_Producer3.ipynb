{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "486a25fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from json import dumps\n",
    "from kafka import KafkaProducer\n",
    "import random\n",
    "import datetime as dt\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d984c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV():\n",
    "    climate_streaming_data = pandas.read_csv('hotspot_TERRA_streaming.csv')\n",
    "    streaming_data = []\n",
    "    for _, row in climate_streaming_data.iterrows(): # Iterate through each row in the CSV\n",
    "        data_point = {} # Create dictionary for individual row & format data appropriately.\n",
    "        data_point['latitude'] = float(row['latitude'])\n",
    "        data_point['longitude'] = float(row['longitude'])\n",
    "        data_point['confidence'] = float(row['confidence'])\n",
    "        data_point['surface_temperature_celcius'] = float(\n",
    "            row['surface_temperature_celcius'])\n",
    "\n",
    "        streaming_data.append(data_point)\n",
    "\n",
    "    return streaming_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89695196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def publish_message(producer_instance, topic_name, data):\n",
    "    try:\n",
    "        producer_instance.send(topic_name, value=data)\n",
    "        producer_instance.flush()\n",
    "        print('Message published successfully. Data: ' + str(data))\n",
    "    except Exception as ex:\n",
    "        print('Exception in publishing message.')\n",
    "        print(str(ex))\n",
    "\n",
    "\n",
    "def connect_kafka_producer():\n",
    "    _producer = None\n",
    "    try:\n",
    "        _producer = KafkaProducer( # Added serializer on the producer, which will automatically serialize to JSON string format.\n",
    "            bootstrap_servers=['192.168.1.5:9092'], value_serializer=lambda x: dumps(x).encode('ascii'), api_version=(0, 10))\n",
    "    except Exception as ex:\n",
    "        print('Exception while connecting Kafka.')\n",
    "        print(str(ex))\n",
    "    finally:\n",
    "        return _producer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ca99dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message published successfully. Data: {'latitude': -37.7836, 'longitude': 142.9437, 'confidence': 69.0, 'surface_temperature_celcius': 44.0, 'created_time': '2021-12-31T02:57:01', 'producer_id': 'producer_hotspot_terra'}\n",
      "Message published successfully. Data: {'latitude': -35.9435, 'longitude': 145.6489, 'confidence': 78.0, 'surface_temperature_celcius': 51.0, 'created_time': '2021-12-31T05:31:07', 'producer_id': 'producer_hotspot_terra'}\n",
      "Message published successfully. Data: {'latitude': -36.1376, 'longitude': 145.84, 'confidence': 76.0, 'surface_temperature_celcius': 55.0, 'created_time': '2021-12-31T07:04:46', 'producer_id': 'producer_hotspot_terra'}\n",
      "Message published successfully. Data: {'latitude': -35.7108, 'longitude': 143.7836, 'confidence': 86.0, 'surface_temperature_celcius': 60.0, 'created_time': '2021-12-31T09:36:21', 'producer_id': 'producer_hotspot_terra'}\n",
      "Message published successfully. Data: {'latitude': -35.2363, 'longitude': 143.0004, 'confidence': 91.0, 'surface_temperature_celcius': 69.0, 'created_time': '2021-12-31T23:04:41', 'producer_id': 'producer_hotspot_terra'}\n",
      "Message published successfully. Data: {'latitude': -36.3387, 'longitude': 141.7542, 'confidence': 96.0, 'surface_temperature_celcius': 77.0, 'created_time': '2022-01-01T00:42:41', 'producer_id': 'producer_hotspot_terra'}\n",
      "Message published successfully. Data: {'latitude': -36.3414, 'longitude': 141.0295, 'confidence': 64.0, 'surface_temperature_celcius': 42.0, 'created_time': '2022-01-01T04:14:53', 'producer_id': 'producer_hotspot_terra'}\n",
      "Message published successfully. Data: {'latitude': -37.9378, 'longitude': 142.541, 'confidence': 55.0, 'surface_temperature_celcius': 39.0, 'created_time': '2022-01-01T08:14:20', 'producer_id': 'producer_hotspot_terra'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 33\u001b[0m\n\u001b[1;32m     29\u001b[0m selected_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproducer_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mproducer_hotspot_terra\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     31\u001b[0m publish_message(producer, topic, selected_data)\n\u001b[0;32m---> 33\u001b[0m \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    data = readCSV()\n",
    "    topic = 'Hotspot_TERRA'\n",
    "    producer = connect_kafka_producer()\n",
    "    created_date = dt.datetime(2021, 12, 31)\n",
    "\n",
    "    count = 0\n",
    "\n",
    "    while True:\n",
    "        count += 3\n",
    "\n",
    "        random_number = random.randrange(0, len(data))\n",
    "        selected_data = data[random_number]\n",
    "\n",
    "        if count > 12: # 10 seconds make up a day with 2 sec interval so 5 iterations as we increase the count by 3 \n",
    "            created_date += dt.timedelta(days=1) # Set to next day & reset time back to 0 hours, 0 minutes & 0 seconds.\n",
    "            created_date.replace(hour=0, minute=0, second=0)\n",
    "            count = 0\n",
    "\n",
    "        # Every two seconds, I select a random hour (in the space of 4 hours), random minutes & seconds, to make a more simulated flow of data.\n",
    "        # As the count increases (as it does 4), the next two seconds, will be a random time, keeping the output in sequential & random order.\n",
    "        created_time = created_date + dt.timedelta(\n",
    "            hours=(random.randrange(count - 3, count)), # so the prediction will be in range 0,1 , 2 previous predictions\n",
    "            minutes=(random.randrange(0, 60)),\n",
    "            seconds=(random.randrange(0, 60)))\n",
    "        selected_data['created_time'] = created_time.isoformat()\n",
    "        # print(selected_data['created_time'].strftime(\"%m/%d/%Y, %H:%M:%S\"))\n",
    "        selected_data['producer_id'] = 'producer_hotspot_terra'\n",
    "\n",
    "        publish_message(producer, topic, selected_data)\n",
    "\n",
    "        sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b979f14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
